{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11266,
     "status": "ok",
     "timestamp": 1741690199597,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "bxtJnRHKGL5y",
    "outputId": "6fcc5486-efb0-4158-f033-dd65673036d0"
   },
   "outputs": [],
   "source": [
    "!pip install dlib\n",
    "!pip install mtcnn\n",
    "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
    "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "error",
     "timestamp": 1741704985750,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "xpNYph5TGQCn",
    "outputId": "91ba0a10-a2ff-4e93-e973-026b37726f1d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "#preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "#face detection\n",
    "from mtcnn import MTCNN\n",
    "import dlib\n",
    "\n",
    "#torch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1741691404315,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "_L27Mp-KFjxO",
    "outputId": "f6dce182-3bb9-4299-a32e-c29b0ef4bfb2"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "\n",
    "#put the name of your folder (or the relative path)\n",
    "folder_name = \"Dataset\"\n",
    "folder_path = f\"/content/drive/My Drive/deepfake_det_task3/{folder_name}/\"\n",
    "\n",
    "os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1741691405541,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "5LroFLvxA6cb"
   },
   "outputs": [],
   "source": [
    "def get_image_paths(base_path):\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1741691406773,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "mjEdA700GhOO"
   },
   "outputs": [],
   "source": [
    "real_train_path = os.path.join(folder_path, \"Train\", \"Real\")\n",
    "fake_train_path = os.path.join(folder_path, \"Train\", \"Fake\")\n",
    "real_test_path = os.path.join(folder_path, \"Test\", \"Real\")\n",
    "fake_test_path = os.path.join(folder_path, \"Test\", \"Fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1741691408352,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "x5eVSgkfKPs4"
   },
   "outputs": [],
   "source": [
    "#extract paths and labels for all images of training data\n",
    "real_train_images = get_image_paths(real_train_path)\n",
    "fake_train_images = get_image_paths(fake_train_path)\n",
    "train_set = real_train_images + fake_train_images\n",
    "\n",
    "real_test_images = get_image_paths(real_test_path)\n",
    "fake_test_images = get_image_paths(fake_test_path)\n",
    "test_set = real_test_images + fake_test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741691492539,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "_zxyANIdGkJ9"
   },
   "outputs": [],
   "source": [
    "train_labels = [1] * len(real_train_images) + [0] * len(fake_train_images)\n",
    "test_labels = [1] * len(real_test_images) + [0] * len(fake_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1741691493428,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "-wKvHm9WJe3V"
   },
   "outputs": [],
   "source": [
    "combined = list(zip(train_set, train_labels))  # Combina immagini e etichette\n",
    "random.shuffle(combined)  # Mescola\n",
    "train_set, train_labels = zip(*combined)  # Separa di nuovo\n",
    "\n",
    "# Converti le tuple risultanti in liste (opzionale, ma utile per manipolazioni successive)\n",
    "train_set = list(train_set)\n",
    "train_labels = list(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1741691494645,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "agZ8Ciq28CJP",
    "outputId": "9d0a9d58-70a3-4a83-f1a5-a7aa38412c71"
   },
   "outputs": [],
   "source": [
    "print(\"Train set length: \" + str(len(train_set)) + \" Train label length: \" + str(len(train_labels)))\n",
    "print(\"Test set length: \" + str(len(test_set)) + \" Train label length: \" + str(len(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1741691498057,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "Kq3FFe_-gmXf"
   },
   "outputs": [],
   "source": [
    "def show_images(inputs, labels=None, num_img=8, randomize=True):\n",
    "    \"\"\"\n",
    "    Mostra un insieme di immagini da una lista di percorsi o array NumPy.\n",
    "\n",
    "    Input:\n",
    "        inputs: Lista di percorsi di immagini (str) o immagini come array NumPy (np.ndarray).\n",
    "        labels: Lista di etichette corrispondenti alle immagini (opzionale).\n",
    "        num_img: Numero di immagini da visualizzare (default: 8).\n",
    "        randomize: Se True, seleziona le immagini casualmente (default: True).\n",
    "    \"\"\"\n",
    "    # Se labels è None, crea una lista vuota di etichette\n",
    "    if labels is None:\n",
    "        labels = [None] * len(inputs)\n",
    "\n",
    "    # Combina inputs e labels in una lista di tuple\n",
    "    inputs_and_labels = list(zip(inputs, labels))\n",
    "\n",
    "    # Seleziona casualmente le immagini e le etichette corrispondenti\n",
    "    if randomize:\n",
    "        selected = random.sample(inputs_and_labels, min(num_img, len(inputs)))\n",
    "    else:\n",
    "        selected = inputs_and_labels[:min(num_img, len(inputs))]\n",
    "\n",
    "    # Crea la figura\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, (input_item, label) in enumerate(selected):\n",
    "        # Determina se l'input è un percorso o un'immagine diretta\n",
    "        if isinstance(input_item, str):\n",
    "            # Carica l'immagine dal percorso\n",
    "            img = mpimg.imread(input_item)\n",
    "        elif isinstance(input_item, np.ndarray):\n",
    "            # Usa direttamente l'immagine come array NumPy\n",
    "            img = input_item\n",
    "        else:\n",
    "            print(f\"Tipo di input non supportato: {type(input_item)}\")\n",
    "            continue\n",
    "\n",
    "        # Mostra l'immagine\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')  # Nasconde gli assi\n",
    "        if label is not None:\n",
    "            axes[i].set_title(f\"Label: {bool(label)}\")  # Converte 0/1 in False/True\n",
    "\n",
    "    # Nasconde eventuali subplot vuoti\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "executionInfo": {
     "elapsed": 8086,
     "status": "ok",
     "timestamp": 1741691509039,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "Jk94kDubh43s",
    "outputId": "4bf3296b-55fd-427f-df08-52902387d3da"
   },
   "outputs": [],
   "source": [
    "show_images(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2925,
     "status": "ok",
     "timestamp": 1741691523403,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "18x-ltiomWzn"
   },
   "outputs": [],
   "source": [
    "# Verifica se il file del modello esiste\n",
    "model_path = \"shape_predictor_68_face_landmarks.dat\"\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"File del modello non trovato: {model_path}. \"\n",
    "        \"Scarica il modello da http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\"\n",
    "    )\n",
    "\n",
    "# Inizializza il rilevatore di volti e il predittore di landmark di dlib\n",
    "detector_dlib = dlib.get_frontal_face_detector()\n",
    "predictor_dlib = dlib.shape_predictor(model_path)\n",
    "\n",
    "def extract_landmarks(lista_di_input):\n",
    "    \"\"\"\n",
    "    Estrae i landmark facciali da una lista di percorsi di immagini o da immagini come array NumPy.\n",
    "\n",
    "    Input:\n",
    "        lista_di_input: Lista di percorsi di immagini (str) o immagini come array NumPy (np.ndarray).\n",
    "\n",
    "    Output:\n",
    "        landmarks_list: Lista di array NumPy contenenti i landmark per ogni immagine.\n",
    "                       Se non viene rilevato un volto o si verifica un errore, viene restituito None.\n",
    "    \"\"\"\n",
    "    landmarks_list = []\n",
    "\n",
    "    for input_item in tqdm(lista_di_input, desc=\"Estrazione landmark\"):\n",
    "        try:\n",
    "            # Determina se l'input è un percorso o un'immagine diretta\n",
    "            if isinstance(input_item, str):\n",
    "                # Carica l'immagine dal percorso\n",
    "                image = cv2.imread(input_item)\n",
    "                if image is None:\n",
    "                    print(f\"Immagine non valida: {input_item}\")\n",
    "                    landmarks_list.append(None)\n",
    "                    continue\n",
    "            elif isinstance(input_item, np.ndarray):\n",
    "                # Usa direttamente l'immagine come array NumPy\n",
    "                image = input_item\n",
    "            else:\n",
    "                print(f\"Tipo di input non supportato: {type(input_item)}\")\n",
    "                landmarks_list.append(None)\n",
    "                continue\n",
    "\n",
    "            # Converti in scala di grigi\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Rileva i volti nell'immagine\n",
    "            faces = detector_dlib(image)\n",
    "            if len(faces) == 0:\n",
    "                print(f\"Nessun volto rilevato in: {input_item}\")\n",
    "                landmarks_list.append(None)\n",
    "                continue\n",
    "\n",
    "            # Prendi il volto più grande (se ci sono più volti)\n",
    "            face = max(faces, key=lambda f: f.width() * f.height())\n",
    "\n",
    "            # Estrai i landmark\n",
    "            landmarks = predictor_dlib(gray, face)\n",
    "            landmarks = np.array([[p.x, p.y] for p in landmarks.parts()], dtype=np.int32)\n",
    "\n",
    "            # Aggiungi i landmark alla lista\n",
    "            landmarks_list.append(landmarks)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Errore durante l'elaborazione di {input_item}: {str(e)}\")\n",
    "            landmarks_list.append(None)\n",
    "\n",
    "    return landmarks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1741691528193,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "gSJfLkx9qC1z"
   },
   "outputs": [],
   "source": [
    "def show_images_with_landmarks(images, landmarks, num_images_to_print=8, randomize=True):\n",
    "    \"\"\"\n",
    "    Visualizza le immagini con i landmark disegnati sopra.\n",
    "\n",
    "    Input:\n",
    "        images: Lista di immagini (formato: array NumPy o percorsi di file).\n",
    "        landmarks: Lista di landmark allineati (formato: array NumPy di forma (68, 2) o None).\n",
    "        num_images_to_print: Numero di immagini da visualizzare (default: 8).\n",
    "        randomize: Se True, randomizza la selezione delle immagini (default: True).\n",
    "    \"\"\"\n",
    "    # Se randomize è True, seleziona casualmente le immagini da visualizzare\n",
    "    if randomize:\n",
    "        indices = random.sample(range(len(images)), min(num_images_to_print, len(images)))\n",
    "    else:\n",
    "        indices = range(min(num_images_to_print, len(images)))\n",
    "\n",
    "    # Crea una figura con un layout di subplot\n",
    "    num_rows = int(np.ceil(num_images_to_print / 4))\n",
    "    fig, axes = plt.subplots(num_rows, 4, figsize=(15, num_rows * 4))\n",
    "    axes = axes.flatten()  # Appiattisce l'array di assi per facilitare l'iterazione\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        img = images[idx]\n",
    "        landmark = landmarks[idx]\n",
    "\n",
    "        # Mostra l'immagine\n",
    "        if isinstance(img, str):  # Se l'immagine è un percorso di file, caricala\n",
    "            img = plt.imread(img)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')  # Nasconde gli assi\n",
    "\n",
    "        # Disegna i landmark se presenti\n",
    "        if landmark is not None:\n",
    "            axes[i].scatter(landmark[:, 0], landmark[:, 1], c='red', s=10)  # Disegna i punti rossi\n",
    "\n",
    "    # Nasconde eventuali subplot vuoti\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1741691532190,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "TMNXi98ZgMuD"
   },
   "outputs": [],
   "source": [
    "# Inizializza il rilevatore MTCNN\n",
    "detector_mtcnn = MTCNN()\n",
    "\n",
    "def extract_face_data(image_paths):\n",
    "    \"\"\"\n",
    "    Estrae i dati delle facce (landmark, bounding box, ecc.) da una lista di immagini.\n",
    "\n",
    "    Input:\n",
    "        image_paths: Lista di percorsi di immagini.\n",
    "\n",
    "    Output:\n",
    "        face_data_list: Lista di dizionari contenenti i dati delle facce.\n",
    "                       Ogni dizionario contiene:\n",
    "                       - 'box': Coordinate del bounding box (x, y, w, h).\n",
    "                       - 'keypoints': Coordinate dei 5 landmark.\n",
    "                       - 'confidence': Livello di confidenza del rilevamento.\n",
    "    \"\"\"\n",
    "    face_data_list = []\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        # Carica l'immagine\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            print(f\"Immagine non valida: {img_path}\")\n",
    "            face_data_list.append(None)  # Aggiungi None per mantenere l'allineamento\n",
    "            continue\n",
    "\n",
    "        # Rileva i volti e i landmark nell'immagine\n",
    "        results = detector_mtcnn.detect_faces(image, threshold_onet=0.5)\n",
    "        if len(results) == 0:\n",
    "            print(f\"Nessun volto rilevato in: {img_path}\")\n",
    "            face_data_list.append(None)  # Aggiungi None per mantenere l'allineamento\n",
    "            continue\n",
    "\n",
    "        # Prendi il volto con la massima confidenza\n",
    "        face = max(results, key=lambda f: f['confidence'])\n",
    "\n",
    "        # Aggiungi i dati del volto alla lista\n",
    "        face_data_list.append(face)\n",
    "\n",
    "    return face_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1741691533361,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "fOq5l1rjtqxE"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def crop_faces(image_paths, face_data_list, target_size=(224, 224), padding=50):\n",
    "    \"\"\"\n",
    "    Ritaglia le facce dalle immagini originali utilizzando i dati delle facce, aggiungendo un padding.\n",
    "\n",
    "    Input:\n",
    "        image_paths: Lista di percorsi di immagini.\n",
    "        face_data_list: Lista di dizionari contenenti i dati delle facce.\n",
    "        target_size: Dimensione desiderata per le immagini ritagliate (default: 224x224).\n",
    "        padding: Valore di padding da aggiungere al bounding box (default: 10).\n",
    "\n",
    "    Output:\n",
    "        cropped_faces: Lista di immagini ritagliate e ridimensionate.\n",
    "    \"\"\"\n",
    "    cropped_faces = []\n",
    "\n",
    "    for img_path, face_data in zip(image_paths, face_data_list):\n",
    "        if face_data is None:\n",
    "            print(f\"Nessun dato del volto per: {img_path}\")\n",
    "            cropped_faces.append(None)\n",
    "            continue\n",
    "\n",
    "        # Carica l'immagine\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            print(f\"Immagine non valida: {img_path}\")\n",
    "            cropped_faces.append(None)\n",
    "            continue\n",
    "\n",
    "        # Ottieni le coordinate del bounding box\n",
    "        x, y, w, h = face_data['box']\n",
    "\n",
    "        # Applica il padding\n",
    "        x = max(x - padding, 0)  # Evita coordinate negative\n",
    "        y = max(y - padding, 0)  # Evita coordinate negative\n",
    "        w = w + 2 * padding      # Aumenta la larghezza\n",
    "        h = h + 2 * padding      # Aumenta l'altezza\n",
    "\n",
    "        # Assicurati che le coordinate non superino i limiti dell'immagine\n",
    "        x_end = min(x + w, image.shape[1])\n",
    "        y_end = min(y + h, image.shape[0])\n",
    "        w = x_end - x\n",
    "        h = y_end - y\n",
    "\n",
    "        # Ritaglia il volto\n",
    "        face_image = image[y:y+h, x:x+w]\n",
    "\n",
    "        # Ridimensiona l'immagine alla dimensione target\n",
    "        face_image = cv2.resize(face_image, target_size)\n",
    "\n",
    "        # Converti l'immagine in RGB (se necessario)\n",
    "        face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Aggiungi l'immagine ritagliata alla lista\n",
    "        cropped_faces.append(face_image)\n",
    "\n",
    "    return cropped_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1741691535246,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "I8Y_S767ciyP"
   },
   "outputs": [],
   "source": [
    "train_set_short = train_set[:20]\n",
    "train_labels_short = train_labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1741691536875,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "feDrTVmgFLrx"
   },
   "outputs": [],
   "source": [
    "#face_data_list = extract_face_data(train_set_short)\n",
    "#cropped_faces = crop_faces(train_set_short, face_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1741691538480,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "rObL9NTJG3TZ"
   },
   "outputs": [],
   "source": [
    "#show_images(cropped_faces, train_labels_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14324,
     "status": "ok",
     "timestamp": 1741691553611,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "lfQeuWIebyGp",
    "outputId": "7ad933d3-7d4f-4ff6-8437-02dbc956fecc"
   },
   "outputs": [],
   "source": [
    "landmarks = extract_landmarks(train_set_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "executionInfo": {
     "elapsed": 2009,
     "status": "ok",
     "timestamp": 1741691564628,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "e7nkLaAK9Veu",
    "outputId": "87ac170e-cd9e-4be1-d4f9-1db42c35daaf"
   },
   "outputs": [],
   "source": [
    "show_images_with_landmarks(train_set_short, landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1741692557911,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "C6BwNw_F90tA"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_paths (list): Lista di percorsi alle immagini.\n",
    "            labels (list): Lista di etichette.\n",
    "            transform (callable, optional): Trasformazioni da applicare alle immagini.\n",
    "        \"\"\"\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Carica l'immagine dal percorso\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Converti in RGB per sicurezza\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Applica le trasformazioni se sono definite\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1741693437992,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "TLFMDQaMA4Oc",
    "outputId": "5fa16576-a6bb-4e8e-e40f-cdc49bc7fdc6"
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "executionInfo": {
     "elapsed": 494450,
     "status": "error",
     "timestamp": 1741693367071,
     "user": {
      "displayName": "Massimo",
      "userId": "14178866670900170492"
     },
     "user_tz": -60
    },
    "id": "-6WcIQ1TJzlb",
    "outputId": "4127acf6-1761-45b4-b166-3c0e5b7117d1"
   },
   "outputs": [],
   "source": [
    "# Parametri\n",
    "INPUT_SHAPE = (224, 224)  # Dimensione input per ResNet50\n",
    "NUM_CLASSES = 1  # Classificazione binaria (REAL o FAKE)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Percorso del dataset (sostituisci con i tuoi dati)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Ridimensiona l'immagine\n",
    "    transforms.RandomHorizontalFlip(),  # Flip casuale\n",
    "    transforms.ToTensor(),  # Converti in tensore\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalizza\n",
    "])\n",
    "\n",
    "# Crea il dataset personalizzato\n",
    "train_dataset = CustomDataset(train_set, train_labels, transform=transform)\n",
    "test_dataset = CustomDataset(test_set, test_labels, transform=transform)\n",
    "# Crea il DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Carica ResNet50 pre-addestrato (senza i layer fully connected)\n",
    "base_model = models.resnet50(pretrained=True)\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False  # Blocca i pesi di ResNet50 per il transfer learning iniziale\n",
    "\n",
    "# Aggiungi layer personalizzati per la classificazione\n",
    "num_ftrs = base_model.fc.in_features\n",
    "base_model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, NUM_CLASSES),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Modello\n",
    "model = base_model\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Funzione di perdita e ottimizzatore\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Addestramento iniziale (solo i layer personalizzati)\n",
    "print(\"Addestramento della testa del modello...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to('cuda' if torch.cuda.is_available() else 'cpu'), labels.float().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Fine-tuning: sblocca alcuni layer di ResNet50 e riaddestra\n",
    "print(\"Fine-tuning del modello...\")\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = True  # Sblocca tutti i layer\n",
    "\n",
    "# Ottimizzatore con un tasso di apprendimento più basso\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE / 10)\n",
    "\n",
    "# Addestramento con fine-tuning\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to('cuda' if torch.cuda.is_available() else 'cpu'), labels.float().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Salva il modello\n",
    "torch.save(model.state_dict(), \"resnet50_deepfake_model.pth\")\n",
    "print(\"Modello salvato con successo!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMEpOU57zZ0ILL2sZdUwhTM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
